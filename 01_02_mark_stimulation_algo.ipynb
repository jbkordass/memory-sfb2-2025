{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark stimulation intervals algorithmically\n",
    "\n",
    "Tries to detect stimulation intervals in files with sotDCS stimulation. Does not rely on triggers/annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from os import listdir,getcwd\n",
    "from os.path import isdir, join\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.signal import hilbert\n",
    "from scipy.stats import kurtosis\n",
    "from mne.time_frequency import tfr_morlet\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()\n",
    "\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and define thresholds\n",
    "\n",
    "These seem to be experimentally determined.\n",
    "\n",
    "### Note on NAP_1056_T1 (stimulation not working on both sides)\n",
    "- Stimulation on the left seems to have worked, but also has lower amplitudes compared to the right\n",
    "- Choosing the following parameters does in fact detect the stimulation period in question\n",
    "  ```\n",
    "  tfr_lower_thresh = 1e-4 # \"reduce\" detection threshold\n",
    "  picks = [\"Fz\",\"AFz\", \"Cz\", \"Fp2\",\"FC2\"] # only pick right electrodes\n",
    "  ```\n",
    "- using also RHS picks (even with modified threshold) will not lead to detection of the failed stimulation\n",
    "- raising the `tfr_lower_thresh` threshold, also extends the detected stimulation periods (as we would expect)\n",
    "- *Technical note: to do the comparison it seems helpful to run the script twice, i.e. use files where `cutout_raw` already ran by setting the input file ending to `rpac`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = str(\"/media/Linux6_Data/DATA/SFB2\")\n",
    "proc_dir = join(root_dir, \"proc\") # working directory\n",
    "\n",
    "sub_dirs = [item for item in listdir(proc_dir) if isdir(join(proc_dir, item))]\n",
    "\n",
    "n_jobs = 24\n",
    "\n",
    "overwrite = True\n",
    "\n",
    "testing = True # for testing, if True, only run once\n",
    "\n",
    "# include or exclude, ignored if empty\n",
    "exclude = [\n",
    "    #[\"1003\", \"T2\"],\n",
    "    #[\"1064\", \"T2\"]     # wrong tDCS intervals detected\n",
    "]\n",
    "skipDir = []       \n",
    "include = [[\"1002\",\"T2\"]\n",
    "    #[\"1074\", \"T2\"],\n",
    "    ###[\"1002\", \"T1\"], #  PostStimtoEnd fehlt, weil EEG nach letzter Stim endet\n",
    "    ###[\"1015\", \"T3\"], #  PostStimtoEnd sehr kleiner Abschnitt, weil EEG kurz nach der Stim 6 endet\n",
    "    ###[\"1019\", \"T1\"], #  erledigt:  Stim1 + Stim 2 zum Teil markiert; Stim3 nicht detektiert, Stim4 als Stim3 detektiert, Stim5 nicht detektiert, Stim6 als Stim4 detektiert\n",
    "    ###[\"1023\", \"T1\"], #  Stimulation 14 vorhanden aber kein Interval + PostStimtoEnd, weil EEG zu Ende\n",
    "    ###[\"1042\", \"T3\"], #  PostStimtoEnd Markierung tritt nicht direkt nach der letzten Stim, sondern später\n",
    "    ###[\"1074\", \"T2\"], #  Bis zu 4. Stim richtig markiert; nach der 4ten wurde alles als Response/R128 markiert - diese wurden aber entfernt ; Falsch markierte Intervalle: Stimulation 5-10 + entsprechende Bad_Ative Stimulation + Bad_Buffer_Stimulation Marker; kein PostStimtoEnd Marker auch unter Annotation Liste nicht\n",
    "    ###[\"1004\", \"T4\"], #  kein PostStimtoEnd, weil EEG bei letztem Interval endet\n",
    "    ###[\"1023\", \"T4\"], #  erledigt  PreStimulation, PostStim 0 und 1 (plus BAD_Buffer und BAD_active Marker) falsch markiert ; Stimulation 0 nicht detektiert und entfernt // die ersten zwei Stimulation passieren hintereinander - es ist nicht klar welcher der 1 Stim zwischen den beiden ist, weil es gibt kein Interval dazwischen // Diese wurde als PostStim2 etc. entfernt weil falsch markiert; fängt bei Stim3 an - sollte Stim1 sein // Stim 9 + Stim 12 + 13 nicht markiert bzw. wenn man ab Stim 3 zählt dann Stim 11,14,15\n",
    "    ###[\"1036\", \"T4\"], #  PostStim fängt nicht direkt nach Stim_Interval an\n",
    "    ###[\"1042\", \"T4\"], #  ist OK so:  PostStimtoEnd fängt später an, nicht direkt nach der letzten Stim/ Stim4 + Stim 6 nicht detektiert - stattdessen BAD Brainvision concatenation contained Marker - nicht entfernt\n",
    "    ###[\"1056\", \"T4\"], #  Stim 12 ist vorhanden aber nicht der Intervall, weil EEG endet + keine PostStimtoEnd\n",
    "    ###[\"1042\", \"T1\"], #  PostStimtoEnd fängt nicht direkt nach dem interval an\n",
    "    ###[\"1047\", \"T2\"], #  PostStimtoEnd fängt später an, nicht direkt nach letztem marker\n",
    "    ###[\"1056\", \"T4\"], #  Stim 12 ist vorhanden aber nicht der Intervall, weil EEG endet + kein PostStimtoEnd\n",
    "    ###[\"1004\", \"T2\"], #  erledigt!  12 Stims, Sollten aber 13 sein -- Comment/10 Tim a + Comment not usuable marker könnte der 13.Stim sein (nicht entfernt); PostStimtoEnd sehr kleiner Abschnitt, weil EEG endet\n",
    "    ###[\"1013\", \"T3\"], #  PostStimtoEnd kleiner abschnitt, weil EEG endet\n",
    "    ###[\"1038\", \"T1\"], #  Ist OK so\n",
    "    ###[\"1042\", \"T1\"], #  Ist OK so\n",
    "    ###[\"107\", \"T1\"]   #  Ist OK so\n",
    "]\n",
    "# BAD Channel\n",
    "# ---------\n",
    "# Define a List of Bad channel per session manually. Later\n",
    "\n",
    "ses_bad_ch = {#\n",
    "    #\"1019_T1\" : [\"AFz\", \"FC1\", \"CP1\", \"Fz\"],\n",
    "    #\"1023_T4\" : [\"AFz\", \"FC1\", \"Cz\"],\n",
    "    #\"1042_T3\" : [\"Cz\", \"Fz\"]\n",
    "}\n",
    "\n",
    "\n",
    "# Durations\n",
    "# ---------\n",
    "\n",
    "# buffer times before and after stimulation detection timepoints\n",
    "pre_stim_buffer = 20    #pre_stim window ends 20 sec before stimulation onset\n",
    "post_stim_buffer = 15   #post_stim window starts 30 (jevri) sec after stimunlation end\n",
    "\n",
    "# analysis window durations\n",
    "analy_duration = 60 # duration of the (pre/poststim) analysis window\n",
    "last_analy_duration = [] # duration of the last analysis window\n",
    "between_duration = 60\n",
    "\n",
    "# sham stimulation duration, asserted in detecting sham stimulations\n",
    "sham_stim_duration = 60 # in seconds\n",
    "\n",
    "\n",
    "# sotDCS detection algorithm parameters\n",
    "# -------------------------------------\n",
    "\n",
    "post_only = True # if True, only mark the first prestim interval (otherwise mark prestim and poststim for each stimulation)\n",
    "\n",
    "reject_by_annotation = False # Default is \"True\". Changed to \"False\" to only exclude Bad-Channels and no data rejections by annotations named \"bad_*\"  -> only for \"*-rpi.fif\" files.\n",
    "\n",
    "# some threshold parameters to determine when stimulation actually happens\n",
    "tfr_upper_thresh_range = list(np.linspace(0.001,0.01,100)) # go from 0.001 to 0.01 in 100 steps\n",
    "#tfr_upper_thresh_range = list(np.linspace(0.001,0.006,100)) # go from 0.001 to 0.01 in 100 steps\n",
    "#tfr_upper_thresh_range = list(np.linspace(1e-5,0.0018,100)) # go from 0.001 to 0.005 in 100 steps   -> decreased range to grab more stims\n",
    "tfr_lower_thresh = 1e-6 \n",
    "\n",
    "epolen = 10 # length in seconds of epochs the data is cut into for tfr analysis\n",
    "min_stim_duration = 25 # min duration in seconds for a stimulation interval to be considered valid\n",
    "#min_stim_duration = 10\n",
    "#picks = [\"AFz\",\"Fp1\",\"Fp2\"]\n",
    "picks = [\"Fz\",\"AFz\", \"Cz\", \"Fp2\",\"FC2\", \"Fp1\", \"FC1\"] # channels used to determine if stimulation has occured\n",
    "# dur_dict = {344:\"5m\", 165:\"2m\", 73:\"30s\"}\n",
    "\n",
    "\n",
    "# tDCS algorithm parameters\n",
    "# -------------------------\n",
    "peak_width = 1000 # 1000 default, 50 if HP Filter (0.1Hz) and LP Filter (100Hz) in prep\n",
    "peak_height = 3 # 3, height of the peaks in terms of standard deviations of the signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "source": [
    "## Notes on stimulations not working properly\n",
    "Notes from the comments column taken by the ones responsible for the experimentation session.\n",
    "- Lines beginning with an \"→\" have been checked by visually, notes then added after the \"|\" symbol\n",
    "\n",
    "T1\n",
    "- 1024 T1 1. Stimulation\n",
    "- → 1056 T1 1. und 9. Stimulation | 1. Stim in Ordnung, in 8./9. Poststim Impedanzmessungen, 10. Stimulation einseitig und nicht erkannt (Fp2 Fz)\n",
    "- 1069 T1 9. Stimulation unsynchron\n",
    "- 1071 T1 5., 10., 14. und 15. Stimulation (Stim 4/14 nur rechts, Stim 7 nur links)\n",
    "- 1074 T1 9. Stimulation\n",
    "- → 1075 T1 6. einseitig 7./14./15. Stim unsynchron | nur 1.-3. Stim erkannt, 6. Stim nur einseitig rechts, 7. Stim beidseits weniger Signal, vorletzte auch beidseitig weniger, 15 Stimulationen vorhanden aber nicht alle haben die Trigger \"Response/R128\"\n",
    "\n",
    "T2\n",
    "- 1003 T2 1. beiden Stim mit sotDCS statt tDCS\n",
    "- 1020 T2 teilweise nicht synchron\n",
    "- → 1055 T2 1. Stim unsynchron links 2s später | 1. Stim wird erkannt, evtl. unsychron?, kein Trigger in 1. Stim\n",
    "- 1059 T2 \"trigger links hat Stim nicht gezählt\"\n",
    "- → 1063 T2 1./6. Stim | nur 2./5. Stim (von 7) erkannt, 1./6. Stim asynchron\n",
    "- → 1073 T2 1./15. einseitig (rechts) | 1. und 15. Stim nicht erkannt, linksseitig weniger Stimulationssignal ⇒ 15. Stim ist im Poststim-Intervall!!\n",
    "- → 1074 T2 9./10./11. nicht synchron | nach 3. Stim alles stark verrauscht, Stimulationen nicht mehr erkannt, auch solche erkannt, die da nicht sind\n",
    "\n",
    "T3\n",
    "- → 1002 T3 2 mal nur rechtsseitig | 3./4. Stimulation nur einseitig und auch nicht detektiert\n",
    "- 1011 T3 \"linker Stimulator bricht Stim manchmal ab\"\n",
    "- → 1024 T3 \"EEG-Programm Problem\" | sieht eigentlich gut aus. Cz?!\n",
    "- 1042 T3 mehrfache Abbrüche\n",
    "- 1057 T3 12. Stim rechts einseitig\n",
    "- 1063 T3 ab 53. Min 8. Stim nicht synchron\n",
    "- → 1064 T3 11./13. Stim nicht synchron | 11. Stim nicht erkannt, 13. erkannt aber FC2 sieht komisch aus\n",
    "- 1073 T3 4. Stim nur rechts, 2./5./6./10./12./13. Stim nicht synchron\n",
    "\n",
    "T4\n",
    "- → 1006 T4 11. Stim \"zeitversetzt, Akkuprobleme\" | es gibt nur 7 Stim in der Datei, nur 1./2. Stim erkannt\n",
    "- → 1013 T4 \"Akkuprobleme\" | alle 12 Stim erkannt, nichts auffälliges\n",
    "- → 1021 T4 \"nur linker Stimulator\" | eine Stim zu viel erkannt (die letzte), vermutlich durch Rauschen in FC1, FC2\n",
    "- → 1023 T4 Stimulator rechts wollte nicht ausslösen | anfangs Stim detektiert, die da gar nicht sind, später funktionierende Stims nicht erkannt!!!\n",
    "- 1042 T4 \"rechts teilweise nicht ausgelöst\" \n",
    "- → 1057 T4 3 mal einseitig, nach der 12. Stim nicht weiter wegen techn. Problemen | nur 1./2./10. Stim erkannt (von 11), keine offensichtlich einseitige Stim?! \n",
    "- → 1059 T4 1.-9. Stim nicht synchron | wie beschrieben, aber alle korrekt detektiert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes on Problems with detection\n",
    "- the detection algorithm used a bunch of assumptions on the data file\n",
    "- it will necessarily run into problems in the following cases:\n",
    "  + if the stimulation frequency varies (because some stimulations did not work/worked differently through stimulations)\n",
    "    - here \n",
    "  + if the stimulation intervals are varying in length!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_pks(expcs):\n",
    "    newpicks = picks.copy()\n",
    "    #print(new_picks)\n",
    "    for pks in picks:\n",
    "        if pks in expcs:\n",
    "            newpicks.remove(pks)\n",
    "    return newpicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sotDCS_stimulation(filename, outfilename, excludeCH):\n",
    "    \"\"\"\n",
    "    Jevris sotDCS detection algorithm\n",
    "\n",
    "    Rough steps: \n",
    "    1. Compute power spectrum and take the mean over picked channels, use this to construct a function tfr_aschan\n",
    "       that assigns to every timepoint the mean tfr value\n",
    "    2. Iterate through upper threshold range beginning with the highest values\n",
    "    2.1. Iterate through the crossings of the threshold tfr_upper_thresh\n",
    "    2.1.1 Find first crossing of the lower threshold after the minimum stimulation duration\n",
    "    2.1.2 Take this as a \"stimulation interval\" and coninue with the next crossing of the upper thresh after the end of it\n",
    "    2.2. Compute the standard deviation of the durations of these \"stimulation intervals\" found\n",
    "    2.3. If the standard deviation is lower than the current \"winner\" save and continue with next upper threshold in range\n",
    "    3. Assume \"winner\" is the best threshold and save the annotations\n",
    "    \n",
    "    Saves results in as an annotation to the file 'outfilename'.\n",
    "    \"\"\"\n",
    "\n",
    "    ur_raw = mne.io.Raw(filename, preload=True)\n",
    "    raw = ur_raw.copy()\n",
    "        \n",
    "    #raw.info[\"bads\"] = excludeCH\n",
    "    mod_picks = mod_pks(excludeCH)   \n",
    "    \n",
    "    # compute power spectrum to determine the frequency with the highest power ?! \n",
    "    # I guess the idea is that this should be the stimulation\n",
    "    \n",
    "    spectrum = raw.compute_psd(method=\"multitaper\", fmax=2, picks=mod_picks, n_jobs=n_jobs,reject_by_annotation=reject_by_annotation)\n",
    "    #spectrum = raw.compute_psd(method=\"welch\", fmax=2, picks=picks, n_jobs=n_jobs)  # 'welch'(s) Method is working with \"reject_by_annotation=True\" (default)\n",
    "    psd = spectrum.get_data().mean(axis=0)\n",
    "    fmax = spectrum.freqs[np.argmax(psd)]\n",
    "    print(f\"Asserted stimulation frequency is {fmax}\")\n",
    "    # fmax should be sth like 0.75\n",
    "    # maybe it would be a good idea to throw an exception if it is not\n",
    "    \n",
    "    # now cut data into fixed length epochs (epolen specifies the number of seconds, usually 10)\n",
    "    # (note that this would in principle already exclude data annotated with \"BAD\"!)\n",
    "    epochs = mne.make_fixed_length_epochs(raw, duration=epolen, reject_by_annotation=reject_by_annotation)\n",
    "    tfr_epochs = tfr_morlet(epochs, \n",
    "                            n_cycles = 1,\n",
    "                            freqs = [fmax],\n",
    "                            average = False,\n",
    "                            return_itc = False,\n",
    "                            picks = mod_picks, \n",
    "                            n_jobs = n_jobs)\n",
    "    # starting from MNE version 1.7 better use\n",
    "    # tfr_epochs = epochs.compute_tfr(method = \"morlet\", \n",
    "    #                         freqs = [fmax],\n",
    "    #                         average = False,\n",
    "    #                         return_itc = False,\n",
    "    #                         picks = picks, \n",
    "    #                         n_jobs = n_jobs)\n",
    "\n",
    "    # run through all the epochs and find the mean tfr values over all channels\n",
    "    # then concatenate them to a vector of length the number of timepoints in the entire recording (tfr)\n",
    "    tfr = np.zeros(0)\n",
    "    for epo_tfr in tfr_epochs.__iter__():\n",
    "        # take the mean over channels (picks) at every timepoint of the epoch \n",
    "        # i.e. np.mean(epo_tfr[:,0,],axis=0) is a vector of length the number of timepoints (usally 10s * 200Hz)\n",
    "        tfr = np.concatenate((tfr, np.mean(epo_tfr[:,0,],axis=0)))\n",
    "    # now create a dictionary that assigns to every timepoint the mean tfr value\n",
    "    tfr_aschan = np.zeros(len(raw))\n",
    "    tfr_aschan[:len(tfr)] = tfr # possibly tfr is shorter than the recording\n",
    "\n",
    "    # iterate through the threshold range specified above (usually 100 steps)\n",
    "    # as a \"convergence measure\" we take the standard deviation of the durations of the stimulation periods detected\n",
    "    # Remark: probably works best if there are many stimulations in the data!\n",
    "    winner_std = np.inf\n",
    "    for tfr_upper_thresh in tfr_upper_thresh_range:\n",
    "\n",
    "        these_annotations = raw.annotations.copy()\n",
    "\n",
    "        # check where the tfr values are over the upper treshold\n",
    "        # \n",
    "        # this is actually a simple trick to find points in which the threshold is crossed\n",
    "        # the first line assings 0.5 to all points above the threshold and -0.5 to all points below the threshold\n",
    "        # the second line multiplies the values of the first line at timepoint t with the values of the first line at timepoint t+1\n",
    "        # ⇒ if the threshold is crossed, the product is negative\n",
    "        tfr_over_upper_thresh = (tfr_aschan > tfr_upper_thresh).astype(float) - 0.5 # > 0 if above threshold, < 0 if below\n",
    "        tfr_upper_tresh_cross = tfr_over_upper_thresh[:-1] * tfr_over_upper_thresh[1:]\n",
    "        tfr_upper_tresh_cross = np.concatenate((np.zeros(1),tfr_upper_tresh_cross))\n",
    "\n",
    "        # and under the lower threshold\n",
    "        tfr_under_lower_thresh = (tfr_aschan < tfr_lower_thresh).astype(float) - 0.5 # > 0 if below threshold, < 0 if above\n",
    "        tfr_lower_thresh_cross = tfr_under_lower_thresh[:-1] * tfr_under_lower_thresh[1:]\n",
    "        tfr_lower_thresh_cross = np.concatenate((np.zeros(1),tfr_lower_thresh_cross))\n",
    "\n",
    "        # as described above tfr_upper_tresh_cross < 0 are the points where the threshold is crossed\n",
    "        tfr_lower_thresh_cross_idcs = np.where(tfr_lower_thresh_cross < 0)[0]\n",
    "\n",
    "        # if no crossings found, move on \n",
    "        # Remark: no idea why in previous versions this checked twice...\n",
    "        if len(np.where(tfr_upper_tresh_cross < 0)[0]) == 0:\n",
    "            continue\n",
    "\n",
    "        # iterate through points where the upper threshold is crossed, i.e. where we expect a stimulation to begin at\n",
    "        earliest_idx = 0 # earliest index to start searching for crossings of the upper threshold\n",
    "        stim_number = 0 # current stimulation number\n",
    "        for cross_idx in np.nditer(np.where(tfr_upper_tresh_cross < 0)[0]):\n",
    "\n",
    "            # if the crossing is before the earliest index (e.g. because found a stimulation there already), skip\n",
    "            if cross_idx < earliest_idx:\n",
    "                continue\n",
    "\n",
    "            # min_stim_duration is the minimum number of seconds for a stimulation period \n",
    "            # so we compute the index of the end of the minimum stimulation duration\n",
    "            min_stim_duration_end_idx = cross_idx + int(np.round(min_stim_duration * raw.info[\"sfreq\"]))\n",
    "\n",
    "            # do an end of recording check, the length here is just the same as len(raw)\n",
    "            if min_stim_duration_end_idx > len(tfr_under_lower_thresh):\n",
    "                min_stim_duration_end_idx = len(tfr_under_lower_thresh) - 1\n",
    "            # now check if the value at min_stim_duration_end_idx is below the lower threshold\n",
    "            # the ideas is that the tfr values beeing already low means we have a short peak or something else that \n",
    "            # causes tfr to be high, but not a stimulation\n",
    "            if tfr_under_lower_thresh[min_stim_duration_end_idx] > 0: # false alarm; do not mark\n",
    "                earliest_idx = min_stim_duration_end_idx\n",
    "                continue\n",
    "            \n",
    "            # calulate times for the currently asserted stimulation\n",
    "            begin = raw.times[cross_idx] - pre_stim_buffer\n",
    "            # find the first crossing of the lower threshold after the minimum duration\n",
    "            first_reasonable_lower_thresh_cross_idx = tfr_lower_thresh_cross_idcs[tfr_lower_thresh_cross_idcs > min_stim_duration_end_idx][0]\n",
    "            end = raw.times[first_reasonable_lower_thresh_cross_idx]\n",
    "            duration = end - begin\n",
    "\n",
    "            # for the first stimulation set durations for pre and post intervals according to variables set above\n",
    "            if stim_number == 0:\n",
    "                pre_dur = analy_duration\n",
    "                post_dur = between_duration\n",
    "            else:\n",
    "                pre_dur = between_duration\n",
    "                post_dur = between_duration\n",
    "            \n",
    "            these_annotations.append(begin, duration, \"BAD_Active_Stimulation {}\".format(stim_number))\n",
    "            these_annotations.append(end, post_stim_buffer, \"BAD_Buffer_Stimulation {}\".format(stim_number))\n",
    "            # decide if prestim intervals should be annotated for each or only for the first stimulation\n",
    "            if not post_only or not stim_number:\n",
    "                these_annotations.append(begin - pre_dur, pre_dur, \"Pre_Stimulation {}\".format(stim_number))\n",
    "            these_annotations.append(begin + duration + post_stim_buffer, post_dur, \"Post_Stimulation {}\".format(stim_number))\n",
    "            stim_number += 1\n",
    "\n",
    "            # start searching for next crossing only after the end of the \"stimulation\" found\n",
    "            earliest_idx = first_reasonable_lower_thresh_cross_idx\n",
    "\n",
    "        # assess uniformity\n",
    "        # calculate the standard deviation of the durations of the stimulation periods\n",
    "        durations = []\n",
    "        for annot in these_annotations:\n",
    "            if \"Active\" in annot[\"description\"]:\n",
    "                durations.append(annot[\"duration\"])\n",
    "        dur_std = np.array(durations).std()\n",
    "\n",
    "        # if the standard deviation is lower than the current winner, save the current annotations\n",
    "        if dur_std < winner_std and dur_std != 0.:\n",
    "            winner_annot = these_annotations.copy()\n",
    "            winner_std =  dur_std\n",
    "            winner_id = tfr_upper_thresh\n",
    "            winner_stim_idx = stim_number\n",
    "            winner_durations = durations.copy()\n",
    "    \n",
    "    # last post-stimulation period should handled differently\n",
    "    last_annot = winner_annot[-1].copy()\n",
    "\n",
    "    # one way would be to remove the last winner annotation and then add a new one that extends to the end of the recording\n",
    "    # winner_annot.delete(-1)\n",
    "    # winner_annot.append(last_annot[\"onset\"], analy_duration, last_annot[\"description\"])\n",
    " \n",
    "    # instead we decide to just add a new annotation that extends to the end of the recording\n",
    "    last_analy_duration = raw._last_time - (last_annot[\"onset\"] + analy_duration)\n",
    "    winner_annot.append(last_annot[\"onset\"] + analy_duration, last_analy_duration, \"Post_Stimulation_ToEnd\")\n",
    "\n",
    "    print(f\"Threshold of {winner_id} was optimal.\\nDurations:\")\n",
    "    print(winner_durations)\n",
    "    print(f\"Standard deviation (of durations):{winner_std}\")\n",
    "    print(f\"Found {winner_stim_idx} stimulations.\")\n",
    "\n",
    "    # if the standard deviation is too high, we might want to check the results\n",
    "    # if winner_std > 2:\n",
    "    #   breakpoint()\n",
    "\n",
    "    # save the annotations\n",
    "    \n",
    "    raw.set_annotations(winner_annot)\n",
    "    winner_annot.save(outfilename, overwrite=overwrite)\n",
    "\n",
    "    # if we are testing, draw a diagnostic plot of the thresholds and plot with mne\n",
    "    if testing:\n",
    "        import matplotlib.pyplot as plt\n",
    "        %matplotlib qt\n",
    "        fig = plt.figure(figsize=(50, 10))\n",
    "        plt.plot(range(0, len(tfr)), tfr, lw= 1, color = 'slategrey')\n",
    "        # add a line to the plot on the y-axis at the lower threshold value\n",
    "        plt.axhline(y = tfr_lower_thresh, color = 'r', linestyle = '--')\n",
    "        # add a line for the max in the upper threshold range\n",
    "        plt.axhline(y = tfr_upper_thresh_range[np.argmax(tfr_upper_thresh_range)], color = 'g', linestyle = '--')\n",
    "        # and for the min\n",
    "        plt.axhline(y = tfr_upper_thresh_range[np.argmin(tfr_upper_thresh_range)], color = 'g', linestyle = '--')\n",
    "        # add a line for the winner threshold\n",
    "        plt.axhline(y = winner_id, color = 'b', linestyle = '--')\n",
    "        # add a lengend what all the lines are\n",
    "        plt.legend([\"tfr\", \"lower threshold\", \"upper threshold range min\", \"upper threshold range max\", \"winner threshold\"])\n",
    "        # zoom in around the annotation with stim_idx\n",
    "        stim_number = 0 # set to -1 to not zoom in at all, 0 would be the first stimulation\n",
    "        for annot in winner_annot:\n",
    "            if f\"BAD_Active_Stimulation {stim_number}\" in annot[\"description\"]:\n",
    "                plt.xlim(int(annot[\"onset\"] * raw.info[\"sfreq\"]), \n",
    "                         int((annot[\"onset\"] + annot[\"duration\"]) * raw.info[\"sfreq\"]))\n",
    "\n",
    "\n",
    "        # Add a dummy channel to the raw object (for plotting) that contains tfr_aschan\n",
    "        info = mne.create_info(['Dummy:TFR'], raw.info['sfreq'], ['misc'])\n",
    "        tfr_channel = np.ndarray((1, len(tfr_aschan)), buffer=np.array(tfr_aschan)*0.5) \n",
    "        tfr_raw = mne.io.RawArray(tfr_channel, info)\n",
    "        raw.add_channels([tfr_raw], force_update_info=True)\n",
    "\n",
    "        # plot (optional)\n",
    "        raw.pick(picks + ['Dummy:TFR']).plot(block=True, scalings=dict(eeg=20e-3), duration=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_tDCS_stimulation(filename, outfilename):\n",
    "    \"\"\" \n",
    "    Algorithm to find tDCS stimulations in the data based on peak analysis in a channel summation function\n",
    "\n",
    "    Currently does *not* use an optimazation procedure, possibly add that, if the performance is bad with less clear signals.\n",
    "\n",
    "    Rough steps:\n",
    "    1. Sum over all channels in picks to create a function x that has hight peaks where stimulations are\n",
    "    2. Find peaks and assume inverse peaks at stimulation start and end\n",
    "    3. Iterate through the peaks and find the first negative peak after the minimum stimulation duration\n",
    "    4. Annotate the stimulation period and the pre and post stimulation periods\n",
    "    \"\"\"\n",
    "    \n",
    "    ur_raw = mne.io.Raw(filename, preload=True)\n",
    "    raw = ur_raw.copy()\n",
    "    these_annotations = raw.annotations.copy()\n",
    "\n",
    "    # plot (optional)\n",
    "    #raw.pick(picks).plot(block=True, scalings=dict(eeg=20e-3), duration=700)\n",
    "    \n",
    "    # compute sum over the channels in picks and call this function x\n",
    "    x = np.zeros(len(raw))\n",
    "    for pick in picks:\n",
    "        x += raw.get_data(picks=pick).mean(axis=0)\n",
    "    \n",
    "    peaks, _ = find_peaks(x, height=np.mean(x) + peak_height*np.std(x), width=peak_width)\n",
    "    neg_peaks, _ = find_peaks(-x, height=np.mean(x) + peak_height*np.std(x), width=peak_width)\n",
    "    #print(neg_peaks)\n",
    "    earliest_idx = 0 # earliest index to start searching for crossings of the upper threshold\n",
    "    stim_number = 0 # current stimulation number\n",
    "    for peak_index in peaks:\n",
    "\n",
    "        # if the crossing is before the earliest index (e.g. because found a stimulation there already), skip\n",
    "        if peak_index < earliest_idx:\n",
    "            continue\n",
    "\n",
    "        # after first_stim find first element in peaks_100\n",
    "        stim_start_index = peak_index\n",
    "        #print(stim_start_index)\n",
    "        # find next element in neg_peaks_100 that is at least min_stim_duration away\n",
    "        min_stim_duration_end_idx = stim_start_index + int(np.round(min_stim_duration * raw.info[\"sfreq\"]))\n",
    "        \n",
    "        #print(min_stim_duration_end_idx)\n",
    "        # do an end of recording check, the length here is just the same as len(raw)\n",
    "        #print(np.where(neg_peaks > min_stim_duration_end_idx))\n",
    "        if min_stim_duration_end_idx > len(raw):\n",
    "            stim_end_index = len(raw) - 1\n",
    "        else:\n",
    "            stim_end_index = neg_peaks[np.where(neg_peaks > min_stim_duration_end_idx)[0][0]]\n",
    "    \n",
    "        # calulate times for the currently asserted stimulation\n",
    "        begin = raw.times[stim_start_index] - pre_stim_buffer\n",
    "        end = raw.times[stim_end_index]\n",
    "        duration = end - begin\n",
    "\n",
    "        # for the first stimulation set durations for pre and post intervals according to variables set above\n",
    "        if stim_number == 0:\n",
    "            pre_dur = analy_duration\n",
    "            post_dur = between_duration\n",
    "        else:\n",
    "            pre_dur = between_duration\n",
    "            post_dur = between_duration\n",
    "    \n",
    "        these_annotations.append(begin, duration, \"BAD_Active_Stimulation {}\".format(stim_number))\n",
    "        these_annotations.append(end, post_stim_buffer, \"BAD_Buffer_Stimulation {}\".format(stim_number))\n",
    "        # decide if prestim intervals should be annotated for each or only for the first stimulation\n",
    "        if not post_only or not stim_number:\n",
    "            these_annotations.append(begin - pre_dur, pre_dur, \"Pre_Stimulation {}\".format(stim_number))\n",
    "        these_annotations.append(begin + duration + post_stim_buffer, post_dur, \"Post_Stimulation {}\".format(stim_number))\n",
    "        stim_number += 1\n",
    "\n",
    "        # start searching for next crossing only after the end of the \"stimulation\" found\n",
    "        earliest_idx = stim_end_index\n",
    "\n",
    "    # assess uniformity\n",
    "    # calculate the standard deviation of the durations of the stimulation periods\n",
    "    durations = []\n",
    "    for annot in these_annotations:\n",
    "        if \"Active\" in annot[\"description\"]:\n",
    "            durations.append(annot[\"duration\"])\n",
    "    dur_std = np.array(durations).std()\n",
    "\n",
    "    # currently there is no optimization, so the first try yields the winner...\n",
    "    winner_annot = these_annotations.copy()\n",
    "    winner_std =  dur_std\n",
    "    winner_id = -1\n",
    "    winner_stim_idx = stim_number\n",
    "    winner_durations = durations.copy()\n",
    "    \n",
    "    # last post-stimulation period should handled differently\n",
    "    last_annot = winner_annot[-1].copy()\n",
    "\n",
    "    # one way would be to remove the last winner annotation and then add a new one that extends to the end of the recording\n",
    "    # winner_annot.delete(-1)\n",
    "    # winner_annot.append(last_annot[\"onset\"], analy_duration, last_annot[\"description\"])\n",
    " \n",
    "    # instead we decide to just add a new annotation that extends to the end of the recording\n",
    "    last_analy_duration = raw._last_time - (last_annot[\"onset\"] + analy_duration)\n",
    "    winner_annot.append(last_annot[\"onset\"] + analy_duration, last_analy_duration, \"Post_Stimulation_ToEnd\")\n",
    "\n",
    "    # print(f\"Threshold of {winner_id} was optimal.\\nDurations:\")\n",
    "    print(winner_durations)\n",
    "    print(f\"Standard deviation (of durations):{winner_std}\")\n",
    "    print(f\"Found {winner_stim_idx} stimulations.\")\n",
    "\n",
    "    # if the standard deviation is too high, we might want to check the results\n",
    "    # if winner_std > 2:\n",
    "    #   breakpoint()\n",
    "\n",
    "    # save the annotations\n",
    "    raw.set_annotations(winner_annot)\n",
    "    winner_annot.save(outfilename, overwrite=overwrite)\n",
    "\n",
    "    # if we are testing, draw a diagnostic plot of the thresholds and plot with mne\n",
    "    if testing:\n",
    "        import matplotlib.pyplot as plt\n",
    "        fig = plt.figure(figsize=(50, 10))\n",
    "        plt.plot(range(0, len(x)), x, lw= 1, color = 'slategrey')\n",
    "        stim_number = 0 # set to -1 to not zoom in at all, 0 would be the first stimulation\n",
    "        for annot in winner_annot:\n",
    "            if f\"BAD_Active_Stimulation {stim_number}\" in annot[\"description\"]:\n",
    "                plt.xlim(int(annot[\"onset\"] * raw.info[\"sfreq\"]), \n",
    "                         int((annot[\"onset\"] + annot[\"duration\"]) * raw.info[\"sfreq\"]))\n",
    "\n",
    "\n",
    "        # Add a dummy channel to the raw object (for plotting) that contains tfr_aschan\n",
    "        info = mne.create_info(['Dummy:Pick Summation'], raw.info['sfreq'], ['misc'])\n",
    "        dummy_channel = np.ndarray((1, len(x)), buffer=np.array(x)*0.5) \n",
    "        dummy_raw = mne.io.RawArray(dummy_channel, info)\n",
    "        raw.add_channels([dummy_raw], force_update_info=True)\n",
    "\n",
    "        # plot (optional)\n",
    "        raw.pick(picks + ['Dummy:Pick Summation']).plot(block=True, scalings=dict(eeg=20e-3), duration=700)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sham_stimulation(filename, outfilename):\n",
    "    \"\"\" \n",
    "    Detect sham stimulation based on triggers\n",
    "    \"\"\"\n",
    "    raw = mne.io.Raw(join(proc_dir, filename), preload=True)\n",
    "\n",
    "    # we want to add new annotations to the old ones, so begin with these\n",
    "    stim_annots = raw.annotations.copy()\n",
    "    # stim_annots = mne.Annotations([], [], [])\n",
    "\n",
    "    # run through the annotations and try to find begin/end of sham stimulation triggers\n",
    "    # we can assume the annotations are sorted by onset\n",
    "    sham_stims = {}\n",
    "    counted_stim_number = 1\n",
    "    for annot in raw.annotations:\n",
    "        # find the strings \"comment\", \"stim\", \"anf\" or \"end\" using positive lookahead (?=)\n",
    "        # also try to identify the stimulation number (though we rather use our own counter...)\n",
    "        match = re.match(\"(?=.*comment)(?=.*(stim|st))(?=.*(?P<type>begin|end))(?=\\\\D*(?P<number>(\\\\d+))).+\", annot[\"description\"], re.IGNORECASE)\n",
    "        if match:\n",
    "            stim_number = int(match.group(\"number\"))\n",
    "            if not counted_stim_number in sham_stims.keys():\n",
    "                sham_stims[counted_stim_number] = {}\n",
    "\n",
    "            if match.group(\"type\") in [ \"begin\" ]:\n",
    "                if counted_stim_number != stim_number:\n",
    "                    # should not happen, in case it does we print it, but doesn't really matter\n",
    "                    print(f\"Note: Stimulation number does not match the expected number counted {counted_stim_number} != found {stim_number}\")\n",
    "                sham_stims[counted_stim_number][\"begin\"] = annot[\"onset\"]\n",
    "            elif match.group(\"type\") in [ \"end\" ]:\n",
    "                sham_stims[counted_stim_number][\"end\"] = annot[\"onset\"]\n",
    "                counted_stim_number += 1\n",
    "            else:\n",
    "                # should not happen\n",
    "                print(\"Error: unknown type of stimulation annotation\")\n",
    "\n",
    "    durations = []\n",
    "    for stim_number, stim in sham_stims.items():\n",
    "        \n",
    "        # if both begin and end are found, we can just use these\n",
    "        if \"begin\" in stim and \"end\" in stim:\n",
    "            begin = stim[\"begin\"] - pre_stim_buffer\n",
    "            end = stim[\"end\"] + post_stim_buffer\n",
    "        elif \"begin\" in stim: # if only begin is found, we use the sham_stim_duration to determine the end\n",
    "            begin = stim[\"begin\"] - pre_stim_buffer\n",
    "            end = begin + sham_stim_duration + post_stim_buffer\n",
    "        else: # TODO: this is a quick fix, might not be perfect..\n",
    "            begin = 0\n",
    "            end = 0\n",
    "            print(\"Error: Sham stimulation without begin or end found\")\n",
    "        \n",
    "        duration = end - begin\n",
    "        durations.append(duration)\n",
    "        stim_annots.append(begin, duration, f\"BAD_Active_Stimulation {stim_number}\")\n",
    "        stim_annots.append(end, analy_duration, f\"Post_Stimulation {stim_number}\")\n",
    "        if not post_only or stim_number == 1:\n",
    "            stim_annots.append(begin - analy_duration, analy_duration, f\"Pre_Stimulation {stim_number}\")\n",
    "\n",
    "    print(durations)\n",
    "    print(f\"Standard deviation (of durations):{np.std(durations)}\")\n",
    "    print(f\"Found {len(durations)} sham stimulation intervals.\")\n",
    "\n",
    "     # last post-stimulation period should handled differently\n",
    "    last_annot = stim_annots[-1].copy()\n",
    "\n",
    "    # instead we decide to just add a new annotation that extends to the end of the recording\n",
    "    last_analy_duration = raw._last_time - (last_annot[\"onset\"] + analy_duration)\n",
    "    stim_annots.append(last_annot[\"onset\"] + analy_duration, last_analy_duration, \"Post_Stimulation_ToEnd\")\n",
    "\n",
    "    raw.set_annotations(stim_annots)\n",
    "    stim_annots.save(join(proc_dir, outfilename), overwrite=overwrite)\n",
    "\n",
    "    if testing:\n",
    "        # plot (optional)\n",
    "        raw.pick(picks).plot(block=True, scalings=dict(eeg=20e-3), duration=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_preprocessed_files = 0\n",
    "\n",
    "for subdir in sub_dirs:\n",
    "    if subdir in skipDir:\n",
    "        continue\n",
    "    print(f\"{subdir}\".center(80, '-'))\n",
    "    proclist = listdir(join(proc_dir, subdir)) # and in proc directory\n",
    "\n",
    "    print(number_of_preprocessed_files)\n",
    "\n",
    "    for file in proclist:\n",
    "        # if we are testing, only apply preprocessing to one file\n",
    "        if testing and number_of_preprocessed_files > 0:\n",
    "            continue\n",
    "\n",
    "        match = re.match(\"NAP_(?P<subj>\\\\d{4})_(?P<cond>T\\\\d{1})-rp.fif\", file)\n",
    "        if not match:\n",
    "            continue\n",
    "        (subj, cond) = match.groups()\n",
    "        \n",
    "        if [subj, cond] in exclude:\n",
    "            continue\n",
    "        if include and [subj, cond] not in include:\n",
    "            continue\n",
    "        \n",
    "        outname = f\"NAP_{subj}_{cond}-rpa.fif\"\n",
    "        if outname in proclist and not overwrite:\n",
    "            print(f\"{outname} already exists. Skipping...\")\n",
    "            continue\n",
    "           \n",
    "        # now do the actual processing\n",
    "        # ----------------------------\n",
    "        excludeCH = []\n",
    "        if \"_\".join([subj,cond]) in ses_bad_ch:\n",
    "            excludeCH = ses_bad_ch.get(\"_\".join([subj,cond]))\n",
    "            \n",
    "\n",
    "        if subdir == 'sotDCS_anod' or subdir == 'sotDCS_cat':\n",
    "            detect_sotDCS_stimulation(join(proc_dir, subdir, file), join(proc_dir, subdir, outname),excludeCH)\n",
    "        elif subdir == 'tDCS': \n",
    "            detect_tDCS_stimulation(join(proc_dir, subdir, file), join(proc_dir, subdir, outname))\n",
    "        elif subdir == 'sham': \n",
    "            detect_sham_stimulation(join(proc_dir, subdir, file), join(proc_dir, subdir, outname))\n",
    "\n",
    "        number_of_preprocessed_files += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "source": [
    "### Helpers\n",
    "\n",
    "Cells should carry the `no_export` tag that is removed from the output in the .ipynb to .py conversion script `_ipynb_to_py.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "outputs": [],
   "source": [
    "# experiment to see how the threshold crossing detection works\n",
    "tfr_over_upper_thresh = np.array([-0.5, -0.5, -0.5, -0.5, 0.5, 0.5, 0.5, -0.5]).astype(float)\n",
    "print(tfr_over_upper_thresh)\n",
    "tfr_upper_tresh_cross = tfr_over_upper_thresh[:-1] * tfr_over_upper_thresh[1:]\n",
    "tfr_upper_tresh_cross = np.concatenate((np.zeros(1),tfr_upper_tresh_cross))\n",
    "print(tfr_upper_tresh_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "outputs": [],
   "source": [
    "# Only view channels that are used to detect stimulation.\n",
    "raw.copy().pick(picks).plot(block=True, scalings=dict(eeg=20e-3), duration=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "outputs": [],
   "source": [
    "raw.plot(block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "source": [
    "Plot the channel locations of the picks for the stimulation detection. (Code following https://stackoverflow.com/a/66583724)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "outputs": [],
   "source": [
    "# Form the 10-20 montage\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "\n",
    "kept_channels = picks # after running the above code, you could also use raw.ch_names to visualize all channels that are there\n",
    "ind = [i for (i, channel) in enumerate(montage.ch_names) if channel in kept_channels]\n",
    "\n",
    "# Keep only the desired channels\n",
    "montage.ch_names = [montage.ch_names[x] for x in ind]\n",
    "kept_channel_info = [montage.dig[x+3] for x in ind]\n",
    "# Keep the first three rows as they are the fiducial points information\n",
    "montage.dig = montage.dig[0:3]+kept_channel_info\n",
    "montage.remove_fiducials() # this way the electrodes are not plotted outside of the head \n",
    "\n",
    "montage.plot() # no idea why this produces two plots for me..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

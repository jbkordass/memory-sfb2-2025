{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutout/reorganize raw file and annotations\n",
    "\n",
    "~~cut away everything except the desired periods of time before and/or after stimulation~~\n",
    "\n",
    "For now instead of cutting/cropping/etc. just merge raw and annotations again.\n",
    "\n",
    "Reject segments that have been concatenated earlier by replacing the annotation description by one starting with \"BAD\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from os import listdir\n",
    "import re\n",
    "from os.path import isdir, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/media/Linux6_Data/DATA/SFB2\"\n",
    "proc_dir = join(root_dir, \"proc\") # working directory\n",
    "\n",
    "ignordir = [\"SO_epochs_NOdetr\",\"SO_epochs_detr\",\"figs\"]\n",
    "sub_dirs = [item for item in listdir(proc_dir) if isdir(join(proc_dir, item))and item not in ignordir]\n",
    "\n",
    "overwrite = False\n",
    "\n",
    "testing = False # for testing, only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_preprocessed_files = 0\n",
    "\n",
    "for subdir in sub_dirs:\n",
    "\n",
    "    print(f\"{subdir}\".center(80, '-'))\n",
    "    proclist = listdir(join(proc_dir, subdir)) # and in proc directory\n",
    "\n",
    "    for file in proclist:\n",
    "\n",
    "        # if we are testing, only apply step to one file\n",
    "        if testing and number_of_preprocessed_files > 0:\n",
    "            continue\n",
    "\n",
    "        # find out subject id (4 digits) and condition (T1, T2, T3, T4) from file name\n",
    "        match = re.search(\"NAP_(?P<subj>\\\\d{4})_(?P<cond>T\\\\d{1})-rpa.fif\", file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subj = match.group('subj')\n",
    "        cond = match.group('cond')\n",
    "        print(f\"Processing {subj} {cond}\")\n",
    "\n",
    "        #if subj != \"9056\":\n",
    "        #    continue\n",
    "\n",
    "        # set the file name of the output .fif file and check if it already exists in proc_dir\n",
    "        outfile =  f\"NAP_{subj}_{cond}-rpac.fif\"\n",
    "        if outfile in proclist and not overwrite:\n",
    "            print(f\"{outfile} already exists in processing dir. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        number_of_preprocessed_files += 1\n",
    "\n",
    "        # now do the actual processing step\n",
    "        # ---------------------------------\n",
    "\n",
    "        # load up raw and annotations\n",
    "        try:\n",
    "            raw = mne.io.Raw(join(proc_dir, subdir, f\"NAP_{subj}_{cond}-rp.fif\"), preload=True)\n",
    "            annots = mne.read_annotations(join(proc_dir, subdir, file))\n",
    "\n",
    "            # check if there is concatenation point in a post stim interval or in the toend interval - if so reject interval\n",
    "            for annot in annots:\n",
    "                if \"Brainvision concatenation\" in annot[\"description\"]:\n",
    "                    for idx, possibly_relevant_annot in enumerate(annots):\n",
    "                        if \"Pre_Stimulation\" in possibly_relevant_annot or \"Post_Stimulation\" in possibly_relevant_annot[\"description\"] or \"ToEnd\" in possibly_relevant_annot[\"description\"]:\n",
    "                            if possibly_relevant_annot[\"onset\"] < annot[\"onset\"] and possibly_relevant_annot[\"onset\"] + possibly_relevant_annot[\"duration\"] > annot[\"onset\"]:\n",
    "                                annots.rename({ possibly_relevant_annot[\"description\"]: \"BAD [Brainvision concatenation contained]\" }) \n",
    "                                print(f\"Rejecting interval {possibly_relevant_annot[\"description\"]} due to concatenation point.\")\n",
    "                                \n",
    "        except:\n",
    "            print(f\"Error loading raw/stim annotations for {subj} {cond}\")\n",
    "            continue\n",
    "        raw.set_annotations(annots)\n",
    "\n",
    "        raw.save(join(proc_dir, subdir, outfile), overwrite=overwrite)\n",
    "        \n",
    "        # TODO: No idea what that special case is, commented out for now\n",
    "        # special cases\n",
    "        # if subj == \"1026\" and cond == \"anodal\":\n",
    "        #     raw.crop(tmax=4180)\n",
    "\n",
    "        # # run through all the annotations, cutting out the pre or post stimulation ones (ignore stimulation itself)\n",
    "        # raws = []\n",
    "        # for annot in annots:\n",
    "        #     print(annot)\n",
    "\n",
    "        #     match = re.match(\"(.*)_Stimulation (\\d.*)\", annot[\"description\"])\n",
    "        #     if match:\n",
    "        #         (stim_pos, stim_idx) = match.groups()\n",
    "        #         if stim_pos == \"Active\":\n",
    "        #             continue\n",
    "        #         # get the onset and duration times\n",
    "        #         begin, duration = annot[\"onset\"], annot[\"duration\"]\n",
    "        #         end = begin + duration\n",
    "        #         # in case the annotation goes beyond the end of the recording (shouldn't happen anyway)\n",
    "        #         if end > raw.times[-1]:\n",
    "        #             end = raw.times[-1]\n",
    "        #         try:\n",
    "        #             raws.append(raw.copy().crop(begin, end))\n",
    "        #         except:\n",
    "        #             pass\n",
    "\n",
    "        # # if there were no pre/post stimulation periods\n",
    "        # if len(raws) == 0:\n",
    "        #     continue\n",
    "\n",
    "        # print(\"now merging...\")\n",
    "\n",
    "        # # now merge into one file\n",
    "        # raw_cut = raws[0]\n",
    "        # raw_cut.append(raws[1:])\n",
    "        # raw_cut.save(join(proc_dir, subdir, outfile), overwrite=overwrite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "Cells should carry the `no_export` tag that is removed from the output in the .ipynb to .py conversion script `_ipynb_to_py.sh`.\n",
    "\n",
    "Some helpers to explore annotations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "outputs": [],
   "source": [
    "raw.annotations.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "no_export"
    ]
   },
   "outputs": [],
   "source": [
    "events_from_annot, event_dict = mne.events_from_annotations(raw)\n",
    "event_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

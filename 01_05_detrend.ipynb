{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robust detrending and artefact detection\n",
    "~~Roughly following the ideas outlined by Leo in prep_test.py~~\n",
    "\n",
    "Simply apply robust detrending everywhere.. that seems a whole lot cleaner.\n",
    "\n",
    "Leos solution also did not really work well with the cutout version of the intervals. (Somehow times in the annotations did not map to time points after cropping.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use masked robust detrending according to https://doi.org/10.1016/j.jneumeth.2021.109080\n",
    "\n",
    "- Masked events are pre/post stimulation annotations (not the last one that goes unitl the end of the data)\n",
    "- Detrend is only calculated over masked events but applied to the whole data\n",
    "- `create_masked_weight` creates a weight that is passed to the `detrend` function\n",
    "- cf. https://nbara.github.io/python-meegkit/modules/meegkit.detrend.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from os import listdir\n",
    "from os.path import isdir, join\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from meegkit.detrend import detrend, create_masked_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/media/Linux6_Data/DATA/SFB2\"\n",
    "proc_dir = join(root_dir, \"proc\") # working directory\n",
    "\n",
    "sub_dirs = [item for item in listdir(proc_dir) if isdir(join(proc_dir, item))]\n",
    "\n",
    "# parameters\n",
    "analy_duration = 60 # duration of the (pre/poststim) analysis window\n",
    "\n",
    "# detrending parameters\n",
    "detrend_orders = [1, 6]\n",
    "\n",
    "overwrite = True\n",
    "\n",
    "testing = False # for testing, only run once\n",
    "\n",
    "include = []\n",
    "exclude = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_preprocessed_files = 0\n",
    "\n",
    "for subdir in sub_dirs:\n",
    "\n",
    "    print(f\"{subdir}\".center(80, '-'))\n",
    "    proclist = listdir(join(proc_dir, subdir)) # and in proc directory\n",
    "\n",
    "    for file in proclist:\n",
    "\n",
    "        # if we are testing, only apply step to one file\n",
    "        if testing and number_of_preprocessed_files > 0:\n",
    "            continue\n",
    "\n",
    "        # find out subject id (4 digits) and condition (T1, T2, T3, T4) from file name\n",
    "        match = re.search(\"NAP_(?P<subj>\\\\d{4})_(?P<cond>T\\\\d{1})-rpacb.fif\", file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subj = match.group('subj')\n",
    "        cond = match.group('cond')\n",
    "        print(f\"Processing {subj} {cond}\")\n",
    "\n",
    "        if [subj, cond] in exclude:\n",
    "            continue\n",
    "        if include and [subj, cond] not in include:\n",
    "            continue\n",
    "\n",
    "        # set the file name of the output .fif file and check if it already exists in proc_dir\n",
    "        outfile =  f\"NAP_{subj}_{cond}-rpacbd.fif\"\n",
    "        if outfile in proclist and not overwrite:\n",
    "            print(f\"{outfile} already exists in processing dir. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        number_of_preprocessed_files += 1\n",
    "\n",
    "        # now do the actual processing step\n",
    "        # ---------------------------------\n",
    "\n",
    "        try:\n",
    "            raw = mne.io.Raw(join(proc_dir, subdir, file), preload=True)\n",
    "        except:\n",
    "            print(f\"Error loading raw for {subj} {cond}\")\n",
    "            continue\n",
    "\n",
    "        # masked robust detrending\n",
    "        masked_events = np.array([])\n",
    "        annotations = raw.annotations\n",
    "        for idx, annot in enumerate(annotations):\n",
    "            if re.match(\"Pre_Stimulation\", annot['description']):\n",
    "                masked_events = np.append(masked_events, annot['onset'])\n",
    "            if re.match(\"Post_Stimulation\", annot['description']):\n",
    "                masked_events = np.append(masked_events, annot['onset'])\n",
    "            if re.match(\"Post_Stimulation_ToEnd\", annot['description']):\n",
    "                duration = annot['duration']\n",
    "                for i in range(1, int(duration/analy_duration)):\n",
    "                    masked_events = np.append(masked_events, annot['onset'] + i*analy_duration)\n",
    "\n",
    "        X = raw.get_data().T # transpose so the data is organized time-by-channels\n",
    "\n",
    "        weight = create_masked_weight(X, masked_events, tmin = 0, tmax = analy_duration, sfreq = raw.info['sfreq'])\n",
    "\n",
    "        for order in detrend_orders:\n",
    "            X, _, _ = detrend(X, order=order, w=weight) \n",
    "\n",
    "        raw._data = X.T  # overwrite raw data\n",
    "\n",
    "        raw.save(join(proc_dir, subdir, outfile), overwrite=overwrite)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

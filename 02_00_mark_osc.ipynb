{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mark slow and delta oscillations in data and save as raw and epoched formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import math\n",
    "from os import listdir\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from anoar import BadChannelFind\n",
    "from scipy.signal import find_peaks\n",
    "from os.path import isdir, join\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/media/Linux6_Data/DATA/SFB2\"\n",
    "proc_dir = join(root_dir, \"proc\") # working directory\n",
    "ignordir = [\"SO_epochs_NOdetr\",\"SO_epochs_detr\",\"figs\"]\n",
    "sub_dirs = [item for item in listdir(proc_dir) if isdir(join(proc_dir, item))and item not in ignordir]\n",
    "\n",
    "overwrite = True\n",
    "\n",
    "testing = False # for testing, only run once\n",
    "\n",
    "# Define ROIs and alternatives, one Channel or a List is possible:\n",
    "#\n",
    "# e.g.\n",
    "# chan_groups_A = {\"frontal\":[\"Fz\", \"FC1\", \"FC2\"], \"parietal\":[\"Cz\", \"CP1\", \"CP2\"]}\n",
    "# ...  \n",
    "chan_groups_A = {\"frontal\":[\"Fz\"],\n",
    "               \"parietal\":[\"Cz\"]}\n",
    "\n",
    "chan_groups_B = {\"frontal\":[\"Fz\"],     # ROI alternative B, if chan_group_A is in 'bads'\n",
    "               \"parietal\":[\"CP1\"]}\n",
    "\n",
    "chan_groups_C = {\"frontal\":[\"Fz\"],     # ROI alternative C, if chan_group and chan_groups_B is in 'bads' \n",
    "               \"parietal\":[\"CP2\"]}\n",
    "\n",
    "chan_groups_D = {\"frontal\":[\"FC1\"],\n",
    "               \"parietal\":[\"Cz\"]}\n",
    "\n",
    "chan_groups_E = {\"frontal\":[\"FC1\"],     # ROI alternative B, if chan_group_A is in 'bads'\n",
    "               \"parietal\":[\"CP1\"]}\n",
    "\n",
    "chan_groups_F = {\"frontal\":[\"FC1\"],     # ROI alternative C, if chan_group and chan_groups_B is in 'bads' \n",
    "               \"parietal\":[\"CP2\"]}\n",
    "\n",
    "chan_groups_G = {\"frontal\":[\"FC2\"],\n",
    "               \"parietal\":[\"Cz\"]}\n",
    "\n",
    "chan_groups_H = {\"frontal\":[\"FC2\"],     # ROI alternative B, if chan_group_A is in 'bads'\n",
    "               \"parietal\":[\"CP1\"]}\n",
    "\n",
    "chan_groups_I = {\"frontal\":[\"FC2\"],     # ROI alternative C, if chan_group and chan_groups_B is in 'bads' \n",
    "               \"parietal\":[\"CP2\"]}\n",
    "\n",
    "\n",
    "\n",
    "chan_groups = [chan_groups_A,chan_groups_B,chan_groups_C,chan_groups_D,chan_groups_E, chan_groups_F,chan_groups_G,chan_groups_H,chan_groups_I]\n",
    "\n",
    "amp_percentile = 65\n",
    "min_samples = 10\n",
    "# Define SO Freq of interest\n",
    "# Also Lists are possible\n",
    "#minmax_freqs = [(0.16, 1.25), (0.75, 4.25)]\n",
    "#minmax_times = [(0.8, 2), (0.25, 1)]\n",
    "minmax_freqs = [(0.16, 1.25)]\n",
    "minmax_times = [(0.8, 2)]\n",
    "# osc_types = [\"SO\", \"DELTA\"]\n",
    "osc_types = [\"SO\"]\n",
    "include = [\n",
    "          #  [\"1002\", \"T3\"],\n",
    "          #  [\"1023\", \"T4\"],\n",
    "          #  [\"1059\", \"T1\"]\n",
    "]\n",
    "skipped = {\"no_osc\":[], \"few_osc\":[], \"chan\":[], \"ROI\":[]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OscEvent():\n",
    "    # organising class for oscillatory events\n",
    "    def __init__(self, start_time, end_time, peak_time, peak_amp, trough_time,\n",
    "                 trough_amp):\n",
    "        self.start_time = start_time\n",
    "        self.end_time = end_time\n",
    "        self.peak_time = peak_time\n",
    "        self.peak_amp = peak_amp\n",
    "        self.trough_time = trough_time\n",
    "        self.trough_amp = trough_amp\n",
    "        self.event_id = None\n",
    "        self.event_annot = None\n",
    "\n",
    "def check_trough_annot(desc):\n",
    "    # helper function for marking troughs of oscillations\n",
    "    event = None\n",
    "    if \"Trough\" in desc and \"ToEnd\" not in desc:    \n",
    "        event = int(desc[-1]) # Number of Post_stimulation X -> desc[-1] = X\n",
    "    if \"Trough\" in desc and \"ToEnd\" in desc:    \n",
    "        event = 99  \n",
    "    return event\n",
    "\n",
    "def get_annotation(annotations, time):\n",
    "    # does a time period reside in a Post stim annotation?\n",
    "    period = None\n",
    "    for annot in annotations:\n",
    "        if \"Post\" not in annot[\"description\"]:\n",
    "            continue\n",
    "        begin = annot[\"onset\"]\n",
    "        end = begin + annot[\"duration\"]\n",
    "        if time > begin and time < end:\n",
    "            period = annot[\"description\"]\n",
    "    return period\n",
    "\n",
    "def osc_peaktroughs(osc_events):\n",
    "    # get peaks and troughs of an OscEvent instance\n",
    "    peaks = []\n",
    "    troughs = []\n",
    "    \n",
    "    for oe in osc_events:\n",
    "        peaks.append(oe.peak_amp)\n",
    "        troughs.append(oe.trough_amp)\n",
    "        \n",
    "    peaks, troughs = np.array(peaks), np.array(troughs)\n",
    "    return peaks, troughs\n",
    "\n",
    "def mark_osc_amp(osc_events, amp_thresh, chan_name, mm_times, osc_type,\n",
    "                 raw_inst=None):\n",
    "    # \n",
    "    osc_idx = 0\n",
    "    for oe in osc_events:\n",
    "        if raw_inst is not None:\n",
    "            event_annot = get_annotation(raw_inst.annotations,\n",
    "                                         oe.start_time)\n",
    "            if event_annot is None:\n",
    "                continue\n",
    "        else:\n",
    "            event_annot = None\n",
    "        pt_time_diff = oe.trough_time - oe.peak_time\n",
    "        time_diff = oe.end_time - oe.start_time\n",
    "        pt_amp_diff = oe.peak_amp - oe.trough_amp\n",
    "        if pt_amp_diff > amp_thresh and mm_times[0] < time_diff < mm_times[1]:\n",
    "            oe.event_id = \"{} {} {}\".format(chan_name, osc_type, osc_idx)\n",
    "            oe.event_annot = event_annot\n",
    "            osc_idx += 1\n",
    "\n",
    "\n",
    "def is_timepoint_in_intervals(tp, onsets, durations):\n",
    "    for onset, duration in zip(onsets, durations):\n",
    "        if onset <= tp <= (onset + duration):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_preprocessed_files = 0\n",
    "\n",
    "for subdir in sub_dirs:\n",
    "\n",
    "    print(f\"{subdir}\".center(80, '-'))\n",
    "    proclist = listdir(join(proc_dir, subdir)) # and in proc directory\n",
    "    save_dir = join(proc_dir,subdir)\n",
    "    for file in proclist:\n",
    "\n",
    "        # if we are testing, only apply step to one file\n",
    "        if testing and number_of_preprocessed_files > 0:\n",
    "            continue\n",
    "\n",
    "        # find out subject id (4 digits) and condition (T1, T2, T3, T4) from file name\n",
    "        match = re.search(\"NAP_(?P<subj>\\\\d{4})_(?P<cond>T\\\\d{1})-rpacbi.fif\", file)\n",
    "        if not match:\n",
    "            continue\n",
    "        subj = match.group('subj')\n",
    "        cond = match.group('cond')\n",
    "\n",
    "        if include and [subj, cond] not in include:\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {subj} {cond}\")\n",
    "\n",
    "        # set the file name of the output .fif file and check if it already exists in proc_dir\n",
    "        outfile =  f\"NAP_{subj}_{cond}-rpaco.fif\"\n",
    "        if outfile in proclist and not overwrite:\n",
    "            print(f\"{outfile} already exists in processing dir. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        number_of_preprocessed_files += 1\n",
    "\n",
    "        # now do the actual processing step\n",
    "        # ---------------------------------\n",
    "        c_groups_alt = chan_groups.copy()\n",
    "        \n",
    "        for c_groups in c_groups_alt:\n",
    "            print(\"Try ROI: \" + str(c_groups))\n",
    "            raw = mne.io.read_raw(join(proc_dir, subdir, file), preload=True)\n",
    "            picks = mne.pick_types(raw.info, eeg=True)\n",
    "            passed = np.zeros(len(c_groups), dtype=bool)\n",
    "            #print(len(passed))\n",
    "            for idx, (k,v) in enumerate(c_groups.items()):\n",
    "                pick_list = [vv for vv in v if vv not in raw.info[\"bads\"]]\n",
    "                print(\"Try CH: \" + k + \" -- \" + str(pick_list))\n",
    "                if not len(pick_list):\n",
    "                    print(\"No valid channels\")\n",
    "                    skipped[\"chan\"].append(\"{} {} {} {}\".format(subj, cond ,k , v))\n",
    "                    continue\n",
    "                avg_signal = raw.get_data(pick_list).mean(axis=0, keepdims=True)\n",
    "                avg_info = mne.create_info([k], raw.info[\"sfreq\"], ch_types=\"eeg\")\n",
    "                avg_raw = mne.io.RawArray(avg_signal, avg_info)\n",
    "                raw.add_channels([avg_raw], force_update_info=True)\n",
    "                passed[idx] = 1\n",
    "            if all(passed):\n",
    "                # ROIs only, drop everything else\n",
    "                raw.pick_channels(list(c_groups.keys()))\n",
    "                break\n",
    "            else:\n",
    "                continue #mandatory\n",
    "   \n",
    "        if not all(passed):\n",
    "            print(\"Could not produce valid ROIs\")\n",
    "            skipped[\"ROI\"].append(\"{} {}\".format(subj, cond))\n",
    "            continue\n",
    "  \n",
    "        # sort out conditiona and polarity\n",
    "        if subdir == \"sham\":\n",
    "            cond = \"sham\"\n",
    "            polarity = \"anodal\"  \n",
    "        elif subdir == \"sotDCS_anod\":\n",
    "            cond = \"SOstim\"           \n",
    "            polarity = \"anodal\"\n",
    "        elif subdir == \"sotDCS_cat\":\n",
    "            cond = \"SOstim\"      \n",
    "            polarity = \"cathodal\"\n",
    "        elif subdir == \"tDCS\": \n",
    "            cond = \"tDCSstim\"      \n",
    "            polarity = \"anodal\"   \n",
    "        else:\n",
    "            raise ValueError(\"Could not organise condition/polarity\")\n",
    "        # = gap_dict[subj][polarity]\n",
    "        \n",
    "\n",
    "        for minmax_freq, minmax_time, osc_type in zip(minmax_freqs, minmax_times, osc_types):\n",
    "            raw_work = raw.copy()\n",
    "            raw_work.filter(l_freq=minmax_freq[0], h_freq=minmax_freq[1])\n",
    "            first_time = raw_work.first_samp / raw_work.info[\"sfreq\"]\n",
    "\n",
    "            # zero crossings\n",
    "            for k in raw.ch_names:\n",
    "                df_dict = {\"Subj\":[],\"Cond\":[],\"Index\":[], \"ROI\":[], \"Polarity\":[],\n",
    "                        \"OscType\":[], \"OscLen\":[], \"OscFreq\":[]}\n",
    "                pick_ind = mne.pick_channels(raw_work.ch_names, include=[k])\n",
    "                \n",
    "\n",
    "                signal = raw_work.get_data()[pick_ind,].squeeze()\n",
    "\n",
    "                # need to add infinitesimals to zeros to prevent weird x-crossing bugs\n",
    "                for null_idx in list(np.where(signal==0)[0]):\n",
    "                    if null_idx:\n",
    "                        signal[null_idx] = 1e-16*np.sign(signal[null_idx-1])\n",
    "                    else:\n",
    "                        signal[null_idx] = 1e-16*np.sign(signal[null_idx+1])\n",
    "\n",
    "                zero_x_inds = (np.where((signal[:-1] * signal[1:]) < 0)[0]) + 1\n",
    "                # cycle through negative crossings\n",
    "                neg_x0_ind = 1 if signal[0] < 0 else 2\n",
    "                osc_events = []\n",
    "                Bad_onsets = [onset for onset, desc in zip(raw_work.annotations.onset, raw_work.annotations.description) if \"BAD\" in desc]\n",
    "                Bad_durations = [duration for duration, desc in zip(raw_work.annotations.duration, raw_work.annotations.description) if \"BAD\" in desc]\n",
    "                for zx_ind in range(neg_x0_ind, len(zero_x_inds)-2, 2):\n",
    "                    idx0 = zero_x_inds[zx_ind]\n",
    "                    idx1 = zero_x_inds[zx_ind+1]\n",
    "                    idx2 = zero_x_inds[zx_ind+2]\n",
    "                    if (idx1 - idx0) < min_samples or (idx2 - idx1) < min_samples:\n",
    "                        continue\n",
    "                    time0 = raw_work.first_time + raw_work.times[idx0]\n",
    "                    time1 = raw_work.first_time + raw_work.times[idx2]\n",
    "                    peak_time_idx = np.min(find_peaks(signal[idx1:idx2])[0]) + idx1\n",
    "                    trough_time_idx = np.argmin(signal[idx0:idx1]) + idx0\n",
    "                    peak_amp, trough_amp = signal[peak_time_idx], signal[trough_time_idx]\n",
    "                    peak_time = raw_work.first_time + raw_work.times[peak_time_idx]\n",
    "                    trough_time = raw_work.first_time + raw_work.times[trough_time_idx]\n",
    "                    # Reject SO-candidates if first zerocrossing time is in a Bad Timespan\n",
    "                    if not is_timepoint_in_intervals(time0, Bad_onsets, Bad_durations):\n",
    "                        osc_events.append(OscEvent(time0, time1, peak_time,\n",
    "                                                peak_amp, trough_time, trough_amp))\n",
    "\n",
    "                # Reject SO-candidates if length is to short or to long: minTime < SOlength <maxTime\n",
    "                osc_events = [oe for oe in osc_events if (oe.end_time-oe.start_time)>minmax_time[0] and \n",
    "                            (oe.end_time-oe.start_time)<minmax_time[1]]\n",
    "                \n",
    "                peaks, troughs = osc_peaktroughs(osc_events)\n",
    "                amps = peaks - troughs\n",
    "                amp_thresh = np.percentile(amps, amp_percentile)\n",
    "\n",
    "                print(\"Amp-thresh: \" + str(amp_thresh))\n",
    "\n",
    "                mark_osc_amp(osc_events, amp_thresh, k, minmax_time, osc_type,\n",
    "                            raw_inst=raw_work)\n",
    "                marked_oe = [oe for oe in osc_events if oe.event_id is not None]\n",
    "                if len(marked_oe):\n",
    "                    for moe_idx, moe in enumerate(marked_oe):\n",
    "                        if moe_idx == 0:\n",
    "                            new_annots = mne.Annotations(moe.start_time,\n",
    "                                                            moe.end_time-moe.start_time,\n",
    "                                                            \"{} {}\".format(moe.event_id, moe.event_annot),\n",
    "                                                            orig_time=raw_work.annotations.orig_time)\n",
    "                        else:\n",
    "                            new_annots.append(moe.start_time, moe.end_time-moe.start_time,\n",
    "                                                \"{} {}\".format(moe.event_id, moe.event_annot))\n",
    "                        new_annots.append(moe.trough_time, 0,\n",
    "                                            \"Trough {} {}\".format(moe.event_id, moe.event_annot))\n",
    "                        new_annots.append(moe.peak_time, 0,\n",
    "                                            \"Peak {} {}\".format(moe.event_id, moe.event_annot))\n",
    "                    new_annots.save(join(save_dir,\n",
    "                                        f\"osc_NAP_{subj}_{cond}_{k}_{osc_type}_{polarity}-annot.fif\"),\n",
    "                                    overwrite=True)\n",
    "                    raw.set_annotations(new_annots)\n",
    "                else:\n",
    "                    skipped[\"no_osc\"].append(\"{} {} {} {} {}\".format(subj, cond, k, osc_type, polarity))\n",
    "                    print(\"\\nNo oscillations found. Skipping.\\n\")\n",
    "                    continue\n",
    "\n",
    "                events = mne.events_from_annotations(raw, check_trough_annot)\n",
    "                \n",
    "                for event_idx, event in enumerate(events[0][:,-1]):\n",
    "                    eve = event.copy()\n",
    "                    df_dict[\"Index\"].append(int(eve))\n",
    "                    df_dict[\"Subj\"].append(subj)\n",
    "                    df_dict[\"Cond\"].append(cond)\n",
    "                    df_dict[\"Polarity\"].append(polarity)\n",
    "                    #df_dict[\"Gap\"].append(gap)\n",
    "                    df_dict[\"ROI\"].append(k)\n",
    "                    df_dict[\"OscType\"].append(osc_type)\n",
    "                    df_dict[\"OscLen\"].append(marked_oe[event_idx].end_time - marked_oe[event_idx].start_time)\n",
    "                    df_dict[\"OscFreq\"].append(1/df_dict[\"OscLen\"][-1])\n",
    "\n",
    "                df = pd.DataFrame.from_dict(df_dict)\n",
    "                epo = mne.Epochs(raw, events[0], tmin=-2.5, tmax=2.5, detrend=1,\n",
    "                                baseline=None, metadata=df, event_repeated=\"drop\",\n",
    "                                reject={\"eeg\":5e-4}).load_data()\n",
    "                # Checking metadata\n",
    "                assert isinstance(epo.metadata, pd.DataFrame)\n",
    "                print(\"######################################\")\n",
    "                print(epo.metadata)\n",
    "                print(\"######################################\")\n",
    "                #if len(epo) < 25:\n",
    "                #    skipped[\"few_osc\"].append(\"{} {} {} {} {}\".format(subj, cond, k, osc_type, polarity))\n",
    "                #    continue\n",
    "                raw.save(join(save_dir, f\"osc_NAP_{subj}_{cond}_{k}_{osc_type}_{polarity}-raw.fif\"),\n",
    "                        overwrite=True)\n",
    "                epo.save(join(save_dir, f\"osc_NAP_{subj}_{cond}_{k}_{osc_type}_{polarity}-epo.fif\"),\n",
    "                        overwrite=True)\n",
    "\n",
    "    # with open(join(proc_dir, \"skipped_record.pickle\"), \"wb\") as f:\n",
    "    #     pickle.dump(skipped, f)\n",
    "\n",
    "    print(f\"Skipped: {skipped}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
